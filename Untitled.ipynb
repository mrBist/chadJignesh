{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./model_interface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_interface.model import FakeNewsDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer,BertModel\n",
    "\n",
    "\n",
    "class BERTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BERTModel,self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(768,6)\n",
    "\n",
    "    def forward(self,ids,mask,token_type_ids):\n",
    "        _, o2 = self.bert(ids, attention_mask=mask,token_type_ids=token_type_ids)\n",
    "        bo = self.dropout(o2)\n",
    "        return self.out(bo)\n",
    "\n",
    "class FakeNewsDetector():\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        # self.model = torch.load(model_path, map_location='cpu')\n",
    "        self.model = BERTModel()\n",
    "        print(\"loading model\")\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "        print(\"model loaded\")\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                            do_lower_case=True)\n",
    "        \n",
    "        self.labels = {0:'disagree', 1:'agree', 2:'discuss', 3:'unrelated'}\n",
    "        self.num_classes = len(self.labels)\n",
    "        self.max_len = 512\n",
    "        print(\"init done\")\n",
    "    \n",
    "    def verifyClaim(self, claim, reference):\n",
    "        \n",
    "        #print(\"claim: \", claim)\n",
    "        #print(\"reference: \", reference)\n",
    "        \n",
    "        #encode batch of sentences\n",
    "        encoded_data = self.tokenizer(\n",
    "            reference,\n",
    "            claim,\n",
    "            add_special_tokens=True,   \n",
    "            max_length=self.max_len,\n",
    "            truncation = True,\n",
    "            padding = \"longest\",\n",
    "            return_tensors = \"pt\"\n",
    "        )   \n",
    "        \n",
    "        # get ids and attention masks\n",
    "        ids = encoded_data['input_ids']\n",
    "        token_type_ids = encoded_data['token_type_ids']\n",
    "        mask = encoded_data['attention_mask']\n",
    "        \n",
    "       \n",
    "\n",
    "        # pass through the model\n",
    "        outputs = self.model(ids, mask, token_type_ids)\n",
    "        \n",
    "        # get probability using softmax\n",
    "        print(outputs.shape)\n",
    "        outputs = torch.softmax(outputs, dim= -1).cpu().detach().numpy()\n",
    "\n",
    "        predicted_classes = np.argmax(outputs, axis = -1)\n",
    "        confidence_scores = np.max(outputs, axis = -1)\n",
    "        \n",
    "  #      classes = self.labels[predicted_classes]\n",
    "        \n",
    "        return  predicted_classes, confidence_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"./Resources\", \"model\", \"finetuned_BERT_epoch_5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n",
      "model loaded\n",
      "init done\n"
     ]
    }
   ],
   "source": [
    "F = FakeNewsDetector(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2], dtype=int64), array([0.9051874], dtype=float32))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.verifyClaim([\"Hello I am good\"], [\"I am not good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                            do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"Hello I am good\",\"make good\"], [\"I am not good\", \"not so much\"], return_tensors = \"pt\", padding = \"longest\")[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
